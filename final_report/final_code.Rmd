---
title: "Final Project Code"
author: "Bingkai Wang"
output: 
  html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The question is:
Perform an analysis of "data scientist" jobs listed on job boards and on the employment pages of major companies. What are the most common skills that employers look for? What are the most unique skills that employers look for? Where are the types of companies that employ the most data scientists?

```{r library, message= FALSE, warning= FALSE}
packages <- c("rvest", "dplyr", "stringr", "tidytext", "ggplot2", "ggmap", "wordcloud", 
              "cowplot", "huxtable")
for (i in packages){
  if(!require(i,character.only = T,quietly=T,warn.conflicts = F)){
    install.packages(i, repos = "http://cran.us.r-project.org")
  }
  require(i,character.only = T,quietly=T,warn.conflicts = F)
}

library(rvest) # web scraping
library(dplyr) # data cleaning
library(stringr); library(tidytext) # text processing
library(ggplot2);library(ggmap);library(wordcloud); library(cowplot) # data visualization
library(huxtable) # making tables in rmarkdown
```

### Step 1 Scraping data from Glassdoor.com with job title 'data scientist'

In this step, we use package **rvest** to scrape and collect raw data for company name, location (city, state), job description, company size, salary, rating and industry. We then output a csv file containing these information.

**Since collecting data takes long time, the following code chunk is not evaluated in this file. Instead, we load the raw data from 'raw_data.csv'.**

```{r web scraping, eval = FALSE}
# Web scraping data from glassdoor.com with job title 'data scientist'
# Using package 'rvest' for scparing and collecting raw data for
# company name, location (city, state) and job description
# Output a csv file containing above information.
# The following code can be easily generalized into thousands of jobs.

#Initializing
webpages <- 5 # 30 jobs per page
company <- rep(NA, webpages * 30)
location <- rep(NA, webpages * 30)
description <- rep(NA, webpages * 30)
companysize <- rep(NA, webpages * 30)
industry <- rep(NA, webpages * 30)
rating <- rep(NA, webpages * 30)
salary <- rep(NA, webpages * 30)
currentpage <- html_session("https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=true&clickSource=searchBtn&typedKeyword=data+sc&sc.keyword=data+scientist&locT=&locId=&jobType=")
ptm <- proc.time()

# scaping
for(i in 1:webpages){
  info <- currentpage %>% html_nodes(".jl") %>% html_text
  rating[(i-1) * 30 + (1:30)] <- str_extract(info, pattern = "^ [:digit:].[:digit:]") %>% trimws
  salary[(i-1) * 30 + (1:30)] <- str_extract(info, pattern = "\\$.*\\(Glassdoor") %>% str_sub(1, -11)
  link <- currentpage %>% html_nodes("#MainCol .flexbox .jobLink") %>% html_attr("href")
  if(length(link) != 30) stop("wrong length of link")
  link <- paste('https://www.glassdoor.com', link, sep = '')
  for(j in 1:30){
    currentlink <- link[j]
    subpage <- html_session(currentlink) # jump to the second level webpage
    if(grepl("glassdoor", subpage$url)){
      company[(i-1) * 30 + j] <- subpage %>% html_node(".padRtSm") %>% html_text()
      location[(i-1) * 30 + j] <- subpage %>% html_node(".subtle") %>% html_text()
      description[(i-1) * 30 + j] <- subpage %>% html_node(".desc") %>% html_text()
      sourcefile <- suppressWarnings(readLines(currentlink))
      pinpoint <- grep("employer", sourcefile)
      sourcefile <- sourcefile[pinpoint[1]+ 0:20]
      current_industry <- sourcefile[str_detect(sourcefile, "\'industry\'")] %>%
        str_extract("\"(.*)\"") %>% 
        str_sub(2, -2)
      industry[(i-1) * 30 + j] <- if(length(current_industry)>0){current_industry}else{NA}
      current_size <- sourcefile[str_detect(sourcefile, "\'size\'")] %>%
        str_extract("\"(.*)\"") %>% 
        str_sub(2, -2)
      companysize[(i-1) * 30 + j] <- if(length(current_size)>0){current_size}else{NA}
    }
    Sys.sleep(1)
  }
  # navigate to next page
  nextpage <- paste0('www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14_IP', 
                     as.character(i+1), '.htm')
  # nextpage <- currentpage %>% html_nodes("#FooterPageNav a") %>% html_attr("href")
  # nextpage <- paste('www.glassdoor.com', nextpage, sep = '')
  currentpage <- html_session(nextpage)
  
  Sys.sleep(5)
}
proc.time() - ptm

# preprocessing location data for output
location <- trimws(location)
type1_indi <- grepl("[[:alpha:]]", str_sub(location, 1, 1))
location[!type1_indi] <- sapply(location[!type1_indi], 
                                function(s) substr(s, 4, nchar(s)))
location <- location %>% str_split(", ") 
for(i in 1: (webpages*30)){
  n <- length(location[[i]])
  if(n == 1){
    location[[i]] <- c(NA, NA)
  }else if(n > 2){
    location[[i]] <- location[[i]][-(1:(n-2))]
  }
}
location <- t(as.data.frame(location))

#output data frame
demo_raw_data <- data.frame(company = trimws(company), 
                            rating = as.numeric(rating),
                            salary = salary,
                            city = location[,1], 
                            state = location[,2], 
                            description = description,
                            companysize = companysize,
                            industy = str_replace_all(industry, "&amp;", "&"))
rownames(demo_raw_data) <- NULL

write.csv(demo_raw_data, "raw_data.csv")
```

The raw data looks like:

```{r show demo_data, echo = FALSE}
demo_raw_data <- read.csv("raw_data.csv")
data_for_display <- head(demo_raw_data)
data_for_display$description <- data_for_display$description %>%
  substr(1, 80) %>%
  paste0('...', sep = '')
print(data_for_display)
```

***

### Step 2 Identifying skills from job description and data cleaning

```{r cleaning}
raw_data <- read.csv(file.path("raw_data.csv"), stringsAsFactors = F)

raw_data$description <- tolower(raw_data$description) #description to lower case
raw_data$companysize <- str_replace_all(raw_data$companysize, "10000--1", "10000+")
raw_data$salary <- str_extract_all(raw_data$salary, "\\$[[:digit:]]*") %>%
  sapply(function(x) {str_sub(x, 2, -1) %>% as.numeric %>% mean})

# generate dictionary of skills
seg <- str_split(raw_data$description, ",|:|[.] | and | or | ;") %>% unlist %>% trimws
seg_word_count <- seg %>% sapply(str_count,"\\S+") %>% as.vector()
seg <- seg[seg_word_count < 3 & seg_word_count != 0] %>% tolower()
dictionary <- data.frame(skill = seg, stringsAsFactors = F) %>%
  group_by(skill) %>%
  tally() %>%
  filter(n > 50) %>%
  arrange(desc(n))
stop_words <- c("color", "religion", "national origin", "sexual orientation", "etc.",
                "age", "sex", "disability", "gender identity", "responsibilities",
                "design", "analytics", "marital status", "analysis", "gender",
                "develop", "tools", "veteran status", "dental", "implement", NA,
                "complex", "pregnancy", "processes", "race", "ancestry", "build",
                "ca", "data", "maintain", "technology", "product managers", "e.g", "etc",
                "experience", "analyze", "genetic information", "services", "state",
                "development", "mathematics")
dictionary <- dictionary[!(dictionary$skill %in% stop_words), ]

# build skill_company matrix
skill_company_mat <- matrix(NA, nrow = nrow(raw_data), ncol = nrow(dictionary))
colnames(skill_company_mat) <- dictionary$skill
for(i in 1:ncol(skill_company_mat)){
  skill_company_mat[,i] <- 
    str_detect(raw_data$description, 
               pattern = paste0(" ", dictionary$skill[i], "(?: |.|;|,)")) %>% as.numeric
}
clean_data <- cbind(raw_data[,-c(1,7)], skill_company_mat)
saveRDS(clean_data, file = "cleandata.rds")
```

Clean data looks like this:

```{r show_clean_data, echo= FALSE}
head(clean_data)
```

***

### Step 3 Exploratory analysis and Visualization

** The following code chunk is only presented but not evaluated since it takes a long time to generate the map plot. **

```{r visualizaion, eval=FALSE}
# barplot for skills
skill_distr <- data.frame(skills = colnames(clean_data)[-(1:7)],
                          freq = colSums(clean_data[,-(1:7)], na.rm = T))
skill_distr <-filter(skill_distr, freq >= sort(skill_distr$freq, decreasing = T)[10])
plot_skill_distr <- ggplot(skill_distr) +
  geom_col(aes(x = reorder(skills, freq), y = freq, fill = freq)) +
  coord_flip() +
  ggtitle("Top 10 skills desired for DS") + 
  theme(legend.position="none",
        plot.title = element_text(size = 16),
        axis.ticks = element_blank(),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 16),
        axis.title.x = element_text(size = 10)) +
  labs(x = NULL, y = "count")

# barplot for unique skills compared with quantitative analyst
quant_raw <- raw_data <- read.csv("quant.csv", stringsAsFactors = F)
skill_dic <- colnames(clean_data)[-(1:7)]
ds_skill_for_quant <- matrix(NA, nrow(quant_raw), length(skill_dic))
for(i in 1:ncol(ds_skill_for_quant)){
  ds_skill_for_quant[,i] <- 
    str_detect(quant_raw$description, 
               pattern = paste0(" ", skill_dic[i], "(?: |.|;|,)")) %>% as.numeric
}
unique_distr <- data.frame(skills = skill_dic, 
                           difference = colSums(clean_data[,-(1:7)], na.rm = T) - 
                             colSums(ds_skill_for_quant, na.rm = T))
unique_distr <- filter(unique_distr,difference >= sort(unique_distr$difference, decreasing = T)[10])
plot_unique_distr <- ggplot(unique_distr) +
  geom_col(aes(x = reorder(skills, difference), y = difference, fill = difference)) +
  coord_flip() +
  ggtitle("Top 10 unique skills desired for DS") +
  theme(legend.position="none",
        plot.title = element_text(size = 16, hjust = 1),
        axis.ticks = element_blank(),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 16),
        axis.title.x = element_text(size = 10)) +
  labs(x = NULL, y = "difference in frequency")


# bar plot for types of companies
industry_distr <- data.frame(industry = 
                               clean_data$industy[!is.na(clean_data$industy)], 
                             stringsAsFactors = F)
filtration  <- industry_distr %>%
  group_by(industry) %>%
  tally %>%
  filter(n > 25) %>%
  arrange(desc(n))
industry_distr <- right_join(industry_distr, filtration) %>% arrange(desc(n))
plot_industry_distr <- ggplot(industry_distr, aes(x = reorder(industry, n), fill = n)) +
  ggtitle("Top 9 industries hiring DS") +
  labs(x = NULL) +
  geom_bar() +
  coord_flip() +
  theme(legend.position="none",
        plot.title = element_text(size = 16, hjust = 2),
        axis.ticks = element_blank(),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 13),
        axis.title.x = element_text(size = 10))

# map plot for job location
location <- str_c(clean_data$city, clean_data$state, sep = ", ")
location <- data.frame(loc = location[!is.na(location)], stringsAsFactors =  F) %>%
  group_by(loc) %>%
  tally() %>%
  arrange(desc(n)) %>%
  as.data.frame() %>%
  mutate(longi = NA, latti = NA)
for(i in 1:nrow(location)){
  location[i, 3:4] <- geocode(location[i,1]) %>% as.numeric
}
location <- location[location$n > 2, ]
usa_center <- as.numeric(geocode("United States"))
USAMap <- ggmap(get_googlemap(center=usa_center, zoom=4, maptype = "roadmap"), 
                extent="normal")
plot_job_geodistr <- USAMap + geom_point(aes(x = longi, y = latti), data = location, 
                    alpha = 0.6, col = "orange",
                    size = location$n/3) + 
  geom_point(aes(x = longi, y = latti), data = location, 
             alpha = 0.3, col = "blue", size = 1) +
  scale_size_continuous(range = range(location$n)) +
  theme( axis.ticks = element_blank(), 
         axis.line = element_blank(),
         axis.text.x = element_blank(),
         axis.text.y = element_blank(),
         axis.title = element_blank(),
         plot.title = element_text(size = 16)) +
  ggtitle("Geo-distributing of DS positions")


plot_grid(plot_skill_distr, plot_unique_distr,plot_industry_distr, plot_job_geodistr, 
          labels = c("A", "B", "C", "D"), ncol = 2)
```

![Visualization of explortory analysis for Data Scientist (DS) jobs](exploratory_plot.png)

***

### Step 4 Statistical analysis
```{r statistical analysis, message= FALSE, warning=FALSE}
clean_data <- readRDS("cleandata.rds")
complete_data <- clean_data[complete.cases(clean_data), ]

# salary analysis
salary_analysis <- complete_data[,c(3, 8:37)]
lp <- lm(salary~., data = salary_analysis) %>% summary
lp <- lp$coefficients
factors <- lp[lp[,4] < 0.01, ]
factors <- factors[-1,] %>% as.data.frame()
factors <- cbind(skill = row.names(factors), factors)
factors[,4] <- sapply(1:3, function(i) {paste0("(", round(qnorm(0.005,factors[i,2],factors[i,3]),2),            ", ", round(qnorm(0.995, factors[i,2],factors[i,3]),2), ")")})
names(factors) <- c("Skill", "Coefficient", "S.E.", "99% C.I.", "P-value")
factors$Skill <- c("Python", "SAS", "Applied Mathematics")
row.names(factors) <- NULL
ht <- as_hux(factors, add_colnames = T)  %>%
      set_bold(1, everywhere, TRUE)       %>%
      set_bottom_border(c(1,4), everywhere, 0.8) %>%
      set_top_border(1, everywhere, 0.8)
position(ht) <- 'center'
align(ht) <- 'center'
caption(ht) <- 'Skills with significant (p < 0.01) influence on salary'
width(ht) <- 0.9
ht

# salary analysis
top_industry <- complete_data$industy %>% table %>% sort(decreasing = T)
top_industry <- names(top_industry[1:8])
top_state <- complete_data$state %>% table %>% sort(decreasing = T)
top_state <- names(top_state[1:9])
rating_data <- complete_data[(complete_data$industy %in% top_industry) & 
                               (complete_data$state %in% top_state), ]
rating_analysis <- rating_data[,c(2, 3, 6, 5, 7)]
factors <- aov(rating~salary+state+industy+companysize, data=rating_analysis) %>% summary
rating_table <- rbind(factors[[1]][["Mean Sq"]][1:4], factors[[1]][["Pr(>F)"]][1:4]) %>% round(2)
row.names(rating_table) <- c("Mean square", "P-value")
colnames(rating_table) <- c("Salary", "State", "Industry", "Company Size")
rating_table <- cbind(Factor = row.names(rating_table), rating_table)
colnames(rating_table)[1] <- " "
hht <- as_hux(rating_table, add_colnames = T)  %>%
      set_bold(1, everywhere, TRUE)       %>%
      set_bottom_border(c(1,3), everywhere, 0.8) %>%
      set_top_border(1, everywhere, 0.8)
position(hht) <- 'center'
align(hht) <- 'center'
caption(hht) <- 'Factors impacting employee\'s satisfaction'
width(hht) <- 0.8
hht
```